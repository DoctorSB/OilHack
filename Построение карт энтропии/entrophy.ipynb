{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение и обработка данных\n",
    "data = open('input/facie_cube').read().splitlines()[5:]\n",
    "data = pd.DataFrame([x.split(sep= ' ') for x in data]).drop(columns=3).astype(float)\n",
    "data.columns = ['i','j','k','f']\n",
    "\n",
    "# Конвертация индексов к нулевой базе\n",
    "data['i'] = data['i'] - 1\n",
    "data['j'] = data['j'] - 1\n",
    "data['k'] = data['k'] - 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание и заполнение куба данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание куба для хранения данных о литологии\n",
    "i_max, j_max, k_max = data[['i', 'j', 'k']].max().astype(int) + 1\n",
    "cube = np.zeros((i_max, j_max, k_max))\n",
    "\n",
    "# Заполнение куба данными о литологии\n",
    "for index, row in data.iterrows():\n",
    "    i, j, k, f = row\n",
    "    cube[int(i), int(j), int(k)] = f\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление вероятностей для каждого узла ij по всем слоям k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание тензора для хранения векторов вероятности\n",
    "prob_tensor = np.zeros((i_max, j_max, k_max, 5))  # предполагаем 5 уникальных литологий\n",
    "\n",
    "# Вычисление вероятностей для каждой ячейки i, j по всем слоям k\n",
    "for i in range(i_max):\n",
    "    for j in range(j_max):\n",
    "        lithologies = cube[i, j, :].astype(int)\n",
    "        counts = Counter(lithologies)\n",
    "        for lithology, count in counts.items():\n",
    "            if lithology >= 0:  # игнорируем литологии равные -1\n",
    "                prob_tensor[i, j, :, lithology] = count / k_max\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление энтропии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление энтропии\n",
    "entropy_tensor = np.zeros((i_max, j_max, k_max))\n",
    "for i in range(i_max):\n",
    "    for j in range(j_max):\n",
    "        for k in range(k_max):\n",
    "            probabilities = prob_tensor[i, j, k, :]\n",
    "            entropy_tensor[i, j, k] = entropy(probabilities)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Усреднение энтропии по слоям и создание тепловой карты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Усреднение энтропии по слоям k для получения двухмерного DataFrame\n",
    "entropy_df = pd.DataFrame(entropy_tensor.mean(axis=2))\n",
    "\n",
    "# Построение тепловой карты\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(entropy_df, cmap='viridis')\n",
    "plt.title(\"Тепловая карта энтропии\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
